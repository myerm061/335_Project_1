Objective
This project aims to deepen students’ understanding of sorting algorithms by implementing, analyzing, and visualizing the performance of various sorting techniques in Python. Students will gain practical experience in algorithm implementation, performance analysis, and the use of visual aids to demonstrate complex concepts.​
Timeframe
Duration: 1 week
Group Size: 3 students per group
Submission Due Date: February 16, 2026 (11:59pm)
Presentation Date: February 17, 2026
Presentation Time: Maximum of 8 minutes, including a live demo​
Responsibilities
Algorithm Implementers
Focus on coding the sorting algorithms.
Visualization and GUI Developer
Develops the tool for visualizing the sorting process.
Analyst and Presenter
Conducts performance analysis and prepares the presentation.​
Project Instructions
1. Algorithm Implementation
Implement five algorithms in Python: Bubble Sort, Merge Sort, Quick Sort, Radix Sort, and a Linear Search routine for comparison in the analysis.
Ensure your code is well‑commented to explain your logic and the theoretical complexity (best, average, worst‑case Big O) of each algorithm.​
2. Visualization Tool Development
Use matplotlib or Pygame to create a visualization tool that demonstrates the sorting algorithms in action.
The tool should allow users to start, pause, and reset the visualization process and switch between algorithms.​
3. Performance Analysis
Measure the execution time of each algorithm with arrays of various sizes and conditions (e.g., random, already sorted, reverse‑sorted) using Python’s timemodule or timeit.
Document your findings and prepare a comparative analysis explaining why you observe those performance differences in terms of Big O and constants.​
4. Presentation Preparation
Summarize:
Project objective and motivation
Methodology (how you implemented, tested, and measured)
Key findings from performance analysis
Reflections on efficiency and practical applications of each algorithm
Prepare and rehearse a live demo of the visualization tool for your in‑class presentation.​
5. Demo Video & LinkedIn Post
Record a short video of the live demo showing the sorting algorithms’ visualization.
Upload the demo video on LinkedIn with a minimum 200‑word post explaining:
The project’s purpose
What you implemented and analyzed
What you learned and why it matters
Include the hashtags #CSUF #AlgorithmEngineering #Spring2026.
Each group member must post on their own LinkedIn account and take a screenshot of their post. Combine all members’ screenshots into one slide in your presentation.​
6. Presentation Submission
Compile your findings, analysis, and demo into a PowerPoint presentation (target 8–10 minutes; hard limit 8 minutes in class).
Ensure the presentation is well‑structured, engaging, and includes enough information for someone who has not seen your code to understand your work.​
PowerPoint Presentation Content
Title Slide
Project Title
Team Members’ Names
Course Information​
Introduction Slide
Brief overview of the project objective
Why sorting algorithms matter in computer science and real systems​
Algorithms Overview Slide
Short description of each algorithm (Bubble, Merge, Quick, Radix, plus what you used Linear Search for)
Theoretical time complexity and space complexity (Big O)​
Implementation Slide(s)
Challenges faced during implementation and how you solved them
Key Python libraries used (e.g., matplotlib, pygame, time, timeit, random)​
Visualization Tool Slide
Overview of the visualization tool and its features (start, pause, reset, choose algorithm, change input size, etc.)
Screenshots and a brief live demo during the talk​
Performance Analysis Slide(s)
Graphs or tables showing execution times across different array sizes and conditions
Discussion of how each algorithm’s performance scales and how that matches their theoretical Big O behavior​
LinkedIn & Outreach Slide
One slide with all team members’ LinkedIn post screenshots
One or two bullet points on how you explained the project to a broader audience​
Conclusion Slide
Key technical takeaways (e.g., which algorithms are practical at scale and why)
Reflections on teamwork, tooling, and what you would improve with more time​
Q&A Slide
Simple “Questions?” slide to invite discussion.​
Acknowledgments Slide
Credits for any external resources, tutorials, or libraries beyond the standard docs.​
Deliverables
Source code for:
Sorting algorithms
Visualization tool
PowerPoint presentation including:
Design, results, and conclusions
At least one live demo during the in‑class talk
Combined LinkedIn screenshot slide
LinkedIn demo video and 200+ word post (each member), with required hashtags.

Evaluation Criteria (Total: 30 points)​
Your project grade will be based on three main components: (1) Implementation & Visualization, (2) Live Presentation & Demo, and (3) LinkedIn Video Post.​
1. Implementation & Visualization (15 points)
This component evaluates the quality of your algorithmic solution, code, analysis, and how clearly you communicate results through visuals.​
13–15 points (Excellent)
Correctly implements the chosen algorithm(s) in Python with no major bugs; code is well-structured, readable, and follows good practices (meaningful variable names, modular design, helpful comments).​
Demonstrates clear understanding of algorithm design: problem is well-formulated, appropriate algorithmic strategy is selected (e.g., greedy, divide-and-conquer, dynamic programming, graph, etc.), and design decisions are justified.Links to an external site.
Provides correct and thoughtful asymptotic analysis (time and space), with clear identification of input size 
n and complexity class (e.g., On, On log n).Links to an external site.
Includes effective visualizations (plots, diagrams, or tables) that clearly support your claims about performance, behavior, or correctness; visuals are labeled, readable, and referenced in your write-up or slides.​
Shows evidence of testing on meaningful inputs, including edge cases, and explains test results.​
10–12 points (Good)
Algorithm is mostly correct with minor issues or limitations; code runs on typical inputs but may fail or be inefficient on some edge cases.​
Algorithm choice is reasonable but justification is somewhat brief or partially incomplete.Links to an external site.
Provides a mostly correct complexity analysis with minor gaps in explanation or notation.Links to an external site.
Visualizations are present and mostly clear, but may be limited in number, lack some labels, or not fully integrated into the explanation.​
Basic testing is demonstrated but not systematic (few edge cases or limited discussion).​
7–9 points (Developing)
Implementation compiles/runs but has correctness issues, incomplete features, or heavy reliance on hard-coded assumptions.​
Algorithm choice is not clearly motivated, or the connection between the problem and algorithmic pattern is weak.Links to an external site.
Complexity analysis is attempted but contains conceptual errors or is too vague (e.g., “it’s fast” without clear On notation).Links to an external site.
Visualizations are minimal, unclear, or not closely tied to your analysis.​
Limited or unclear testing; test discussion does not convincingly support correctness or performance claims.​
0–6 points (Incomplete / Needs Significant Improvement)
Code does not run, is largely missing, or does not address the stated problem.​
No meaningful algorithmic justification or incorrect use of core concepts from the course.Links to an external site.
No valid complexity analysis provided.Links to an external site.
No useful visualizations, or visuals are unrelated to the algorithm’s behavior.​
Little to no evidence of testing.​
2. Live Presentation & Demo (10 points)
This component evaluates how clearly and professionally you communicate your work in class, including a live demo of your system.​
9–10 points (Excellent)
Clear, well-organized presentation that fits within the time limit and flows logically (problem → approach → algorithm → results → lessons learned).​
Explains the problem context and why it matters in a way that a peer in CPSC 335 can follow.Links to an external site.
Describes the algorithm at the right level of detail (high-level idea, data structures used, complexity) without getting lost in code.Links to an external site.
Live demo runs smoothly: shows key features, representative input/output, and performance behavior; handles minor technical issues professionally.​
All team members participate meaningfully in speaking; delivery is audible, professional, and engaging.​
7–8 points (Good)
Presentation is mostly clear but may have minor organizational issues or slight time mismanagement.​
Problem and approach are explained but with some missing context or details.Links to an external site.
Demo works on at least one meaningful example, though coverage of features or performance may be limited.​
Most team members speak; overall delivery is understandable, with some reliance on notes or slides.​
5–6 points (Developing)
Presentation is somewhat difficult to follow, jumps between topics, or significantly under-/over-shoots the time limit.​
Explanations of the algorithm or complexity are superficial or technically inaccurate.Links to an external site.
Demo is incomplete, fragile, or only shown briefly; key aspects of the system are not demonstrated.​
One or two team members dominate the speaking; others have minimal participation.​
0–4 points (Incomplete / Needs Significant Improvement)
Presentation is missing, extremely short, or lacks structure.​
Little to no explanation of the algorithmic ideas or course concepts.Links to an external site.
No working demo, or demo is not attempted.​
One or more team members do not participate at all without prior arrangement.​
3. LinkedIn Video Post (5 points)
This component evaluates your ability to communicate your project to a professional audience in a concise video posted on LinkedIn.​
5 points (Excellent)
Public or appropriately shared LinkedIn post is completed by the deadline and includes a short video (e.g., 60–180 seconds) introducing the project.​
Video clearly states: who you are, the course, the problem you solved, and the core algorithmic idea or technique used.Links to an external site.
Content is professional in tone and style, with clear audio and readable visuals (screen capture, slides, or brief demo).​
Post includes a brief written description and relevant tags (e.g., #algorithms, #python, #csuf).​
3–4 points (Good)
Video is posted and generally professional but may be missing one element (e.g., weak description of algorithm, short text caption, or minimal tags).​
Audio/visual quality is acceptable, though not polished.​
1–2 points (Developing)
Video is posted but is very brief, unclear, or lacks important context (problem, algorithm, or course).​
Professional tone is inconsistent (e.g., distracting background, informal language) or quality issues make the content hard to follow.​
0 points (Missing)
No LinkedIn video post submitted, or post is not accessible.​
Path to Success
To aim for full credit across all three components:​
Start early on algorithm design and implementation, and connect your approach explicitly to patterns and analysis discussed in class (e.g., greedy, divide-and-conquer, dynamic programming, graph algorithms, Big O).Links to an external site.
Build visualizations and tests while you implement so you can reuse them in your write-up, slides, and demo.Links to an external site.
Rehearse your live presentation and demo as a team to ensure smooth transitions, timing, and working code.​
Script and record your LinkedIn video after the project is stable, focusing on a clear, high-level story rather than low-level code details.
